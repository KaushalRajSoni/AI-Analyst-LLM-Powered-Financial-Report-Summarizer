{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2aPi5iqWfqah"
   },
   "source": [
    "# **Installing Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XjLmFHgDeeaq",
    "outputId": "037f19d6-00ce-4051-d2bb-26660f87b805"
   },
   "outputs": [],
   "source": [
    "pip install transformers torch PyMuPDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BhS1_8hvfyhD"
   },
   "source": [
    "# **Importing Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FfZS_o5iWOhr"
   },
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XWjrfKrcf5eS"
   },
   "source": [
    "# **Load The PDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WRlpF7Yqf9a_"
   },
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "        text += page.get_text()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t5rmUgwqgCEL"
   },
   "source": [
    "# **Chunk the PDF text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "siTHY825gJ5S"
   },
   "outputs": [],
   "source": [
    "def chunk_text(text, max_chunk_length=1000):\n",
    "    paragraphs = text.split(\"\\n\")\n",
    "    chunks = []\n",
    "    current_chunk = \"\"\n",
    "    for para in paragraphs:\n",
    "        if len(current_chunk) + len(para) <= max_chunk_length:\n",
    "            current_chunk += para + \"\\n\"\n",
    "        else:\n",
    "            chunks.append(current_chunk.strip())\n",
    "            current_chunk = para + \"\\n\"\n",
    "    if current_chunk:\n",
    "        chunks.append(current_chunk.strip())\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iA__ik0OgRHT"
   },
   "source": [
    "# **Load LLM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400,
     "referenced_widgets": [
      "aa4a5776d7c4474b9f3523e91b4c811e",
      "5a1224922cf441f7935f9c82741d318d",
      "1407f151663447e19765cbb09b24a58e",
      "63c9bad5b79e4c9296cd69cce7ca5f7f",
      "cfeee3223f7e4b61adcdd4c0889b124f",
      "1be684d2d1a1484093ef0e29760898bc",
      "33bc666abac748acba28f510ee539056",
      "1e2f282e84dd4f07a3a76ccde935e294",
      "d3a88efe6a1e49a8b23adf087912f2c6",
      "dfa33d2936ce42498d92ba871f64b31b",
      "478a4f2a03db482384000e92e046ce78",
      "3f7cb0193b9c49b8a6df82770b9aca7a",
      "5adaf31a556247dda049e312203016c6",
      "616bd50a20884043ae5fc2779d447f59",
      "d381dba518ce48adbd2797c851f8de9b",
      "80634070f82d403ebb2a7aa14f00ffb2",
      "f9fb06858d674f2ba0629caebf569f31",
      "b32565c484904dd3aadf2dc44f79c873",
      "16d93b5f67934781b35c28beaa6d2f9c",
      "3a14bded7f514463b351431fa5a34952",
      "2e2b35e9c1f64b2899e8ec67f2658fc4",
      "af3ed33142f94798b2002d78d729f0da",
      "74563aacad184cb49fe4afdcbd69d750",
      "7f14f40d9ecb4df5aff68f969e21e57b",
      "8e663d8b28964e319da919ed9a4e09b2",
      "cd24548ca8854825a9194ceda9c3ae4a",
      "995f213dfe6e42ebac1fa42501790d99",
      "e959ee097b8a4f9db11ec2b68a0aede5",
      "6c74ed39c3244273ad38b4007ea44af5",
      "58003a1278c649fcadf56652b95ccf07",
      "8c062be74de34c8891fff2584fe8939d",
      "7fd8c435fb6e4f77970480df6d35f282",
      "e2ea38fac17340b284bf2169fd3da7ba",
      "d402992014ce4b07ad439258d3fc05ae",
      "48162f1e74064fce8124273036b3650c",
      "2cf9a3aa00c74656b9a421dcd060abac",
      "5597989edc10442083f8311d41c0e6cd",
      "fe3e851919ec4639ba90d72e853edda8",
      "05421aa82fc547ad87597ff7f6272b3e",
      "9bd9977a9280474cb2afa33028b59480",
      "bf0d12b840a44750af79a22f56174681",
      "f8e5ca31d7ea436c9979bf196640cbb1",
      "221414e59b334d6f9d1c728c30f94357",
      "6e476c0d3056425d99d54f6af09c665c",
      "355c30b4bf62402f98a82581723a9c21",
      "5f1aa324a63f4538b460b8eb22fce4f3",
      "eae3d85534d44473a76be8617c3a2b69",
      "9b1a1dd09b514fc1a5079cbcf5f412a5",
      "53bdc83f5e604fd0b8cfd0fc4a0bef9e",
      "b0d6dbf3cb5a416e9794bf44305a7a16",
      "8b641c2c87e74f958961fd98e34744ba",
      "607ec86e329a40fb8f3852348fc6710e",
      "44cc75730fc54882b6e404dcd97e7348",
      "decc4e1ba488417f834d344102eccf82",
      "740171dda9e1472d8644612e027b4aa3",
      "e7ff3f488d7f44b7bffe5ade2e33e490",
      "f12390d07e744e76aacf62e52db69ee1",
      "c23f972d604b42988a57249a1dcfbf26",
      "2856235baf344a4099d29882429d1e91",
      "510b57b7c0514c6b9077681646af205f",
      "93e5b5d8cd9145e5864a4cdb97666bb2",
      "3d0a608773fd4890b144e8834e0d1ea0",
      "91f98b2f44de42908d5cb4fd2fabf78d",
      "b1266210d978400f91b5ed9a5be9df3e",
      "1c724bb943b94fb8b34bdb8b12458f94",
      "20a998c33478434e81f70557645ea79a",
      "6942a90b2ef9477c92219e414116cebf",
      "401715d5149d4f819b44a3abeb29ae10",
      "8f47bfa46f614769bd3d257d4b5af7d2",
      "4adc58a9b67249cbb751c1eb65530cbc",
      "98d39bb4eb77423e8f3345f275bde5df",
      "d33009ff4b464b2ca7c400fb34e23da4",
      "b4a0bc93cac84f9e8fc7fce89e6723ce",
      "7e21115d07bb4ee2beb37be752b02e8f",
      "60ea5b84ed3142be890079c0120435d2",
      "f0ff181ff7e14114865e0105981e71f8",
      "552a1205e3094fb28c1013883da0aa7d"
     ]
    },
    "id": "v2RkAejpgNo8",
    "outputId": "3db2250a-283f-41cc-d8e0-b89f4327d89f"
   },
   "outputs": [],
   "source": [
    "model_name = \"gpt2-medium\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ROdxKKtad80N"
   },
   "outputs": [],
   "source": [
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    model.config.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "def generate_answer(context, question, max_new_tokens=150):\n",
    "    prompt = f\"Context:\\n{context}\\n\\nQuestion: {question}\\nAnswer:\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=1024, padding=\"max_length\")\n",
    "    outputs = model.generate(\n",
    "        input_ids=inputs[\"input_ids\"],\n",
    "        attention_mask=inputs[\"attention_mask\"],\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        pad_token_id=tokenizer.pad_token_id\n",
    "    )\n",
    "    full_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return full_output.split(\"Answer:\")[-1].strip()\n",
    "\n",
    "def ask_question_over_pdf(pdf_path, question):\n",
    "    full_text = extract_text_from_pdf(pdf_path)\n",
    "    chunks = chunk_text(full_text, max_chunk_length=1000)\n",
    "    answers = []\n",
    "    for i, chunk in enumerate(chunks[:5]):\n",
    "        answer = generate_answer(chunk, question)\n",
    "        answers.append(answer)\n",
    "    return \"\\n\\n---\\n\\n\".join(answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kw8l2DBrgfKF"
   },
   "source": [
    "# **Running The Pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TI2NDhcPgmn6",
    "outputId": "73c3b7a1-ced8-45a9-e1ea-406752b189b5"
   },
   "outputs": [],
   "source": [
    "pdf_path = \"/RIL-Integrated-Annual-Report-2023-24.pdf\"  # Replace with your actual PDF path\n",
    "question = \"What are the key financial highlights?\"\n",
    "print(\"Q:\", question)\n",
    "print(\"A:\", ask_question_over_pdf(pdf_path, question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EMsEhw_Ng5TY"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (Pyodide)",
   "language": "python",
   "name": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
